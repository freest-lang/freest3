\section{Soundness and Completeness}
\label{sec:soundness}

In this section we prove that our algorithm is sound and complete 
with respect to the meta-theory of context-free session types proposed 
by Thiemann and Vasconcelos~\cite{thiemann2016context}.

We start by showing that the bisimulation relation proposed by 
Thiemann and Vasconcelos, $\TypeEquiv$, is equivalent to the 
bisimulation relation obtained from the productions, $\ProdEquiv$. 
Then, based on results from Christensen, H{\"{u}}ttel, 
Stirling~\cite{DBLP:journals/iandc/ChristensenHS95}, Jan{\v{c}}ar 
and Moller~\cite{janvcar1999techniques}, we conclude that our algorithm 
is sound and complete.

\subsection{The bisimilarities coincide}

To ease notation, we will represent $\mathsf{toGrammar}
(\mathsf{freshVar}(\,),S)$ as $\mathsf{toGrammar}(S)$ whenever 
the fresh variable is not relevant in the context.

In the following lemma we prove that the initial (dummy) production 
does not affect equivalence checking.
\begin{lemma}
	Given two session types $S_1, S_2$, 
	\[ X_{S_1} \sim X_{S_2}  \text{ if and only if } 
	\mathsf{toGrammar}(S_1) \sim \mathsf{toGrammar}(S_2).\]
\end{lemma}

\begin{proof}
	By~\eqref{initial_prod}, we have:
	\[ X_{S_1}  \rightarrow \enspace \initialProd\enspace \mathsf{toGrammar}(S_1) 	\]
    \[ X_{S_2}  \rightarrow \enspace \initialProd\enspace \mathsf{toGrammar}(S_2) 	\]

Hence, $X_{S_1}\sim X_{S_2}$ if and only if 
$\mathsf{toGrammar}(S_1) \sim \mathsf{toGrammar}(S_2)$.
\end{proof}

Now we prove that any transition in the \LTS\ has a 
corresponding transition derived from the set of productions.

\begin{lemma}
Given session types $S,S'$ and a label $\ell$,
	\[ \text{if } S \LTSderives[\ell] S' \text{ then } 
	\mathsf{toGrammar}(S) \rightarrow \enspace \ell \enspace \vec Y, \]
	where $\mathsf{toGrammar}(S')$ is prefix of $\vec Y$.
\end{lemma}

\begin{proof}
The proof is done by induction on the structure of the labelled 
transition system (Fig.~\ref{lts}):
\begin{itemize}
	\item If $S\triangleq \skipk$, then $S$ is a terminated 
	      session type, with no further transition. Similarly, 
	      $\mathsf{toGrammar}(S)$ returns $\varepsilon$ and 
	      does not add any production.
	\item If $S\triangleq A$, where $A$ ranges over $!B$ and $?B$, 
	      then $S  \LTSderives[A] \skipk$. On the other hand, 
	      $\mathsf{toGrammar}(X,S)$ returns $X$ and inserts a production $X\rightarrow A$, 
	      i.e., $X\rightarrow A \enspace  \mathsf{toGrammar}(\skipk).$  
	\item If $S \triangleq \alpha$, then $S   \LTSderives[\alpha] \skipk$. 
	      On the other hand, since $\alpha$ does not contain non-terminal 
	      symbols, $\mathsf{toGrammar}(X,S)$ returns $X$ and inserts a production 
	      $X\rightarrow \alpha$, i.e.,\linebreak  $X\rightarrow \alpha \enspace 
	      \mathsf{toGrammar}(\skipk).$
	\item If $S\triangleq \star\{l_i\colon S_i\}_{i\in I}$ then, for each 
          $j\in I$, $S \LTSderives[\star l_j] S_j$. On the other hand, 
          for each $j\in I$, $\mathsf{toGrammar}(X,S)$ returns $X$ and  inserts a production 
          $X\rightarrow \star l_j \enspace \mathsf{toGrammar}(S_j)$.
	\item If $S\triangleq \mu x.S$ and $S[\mu x.S/x] \LTSderives[a] S'$, 
	      then $\mu x.S \LTSderives[a] S'$. By induction hypothesis, 
	      $\mathsf{toGrammar}(X,\mathsf{subst}(x,X,S))$ adds the production 
	      $X \rightarrow a\enspace  \mathsf{toGrammar}(S')$.
	\item If $S\triangleq T;U$ and $T \LTSderives[a] T'$ then $S \LTSderives[a] T';U$. 
	      By induction hypothesis, $\mathsf{toGrammar}(X,T)$ adds the production 
	      $X\rightarrow a \enspace \mathsf{toGrammar}(T')$ to $\mathcal P$.
		Denoting by 
		\begin{align*}
			\vec Y_T &\leftarrow \mathsf{toGrammar}(X,T)\\
			\vec Y_U &\leftarrow \mathsf{toGrammar}(Y,U)
		\end{align*}
		we notice that $\vec Y_T = X \enspace \vec Y_T'$ for some 
		sequence of non-terminal symbols $\vec Y_T'$. By congruence, we have: 
		\[\mathsf{toGrammar}(S) = X \enspace \vec Y_T' \enspace \vec Y_U' 
		\rightarrow a \enspace \mathsf{toGrammar}(T') \enspace \vec  Y_T' 
		\enspace \vec Y_U.\]
	\item If $S\triangleq T;U$, $T$ is a terminated session, with no further 
	      action, and $U \LTSderives[a] U'$ then, by induction hypothesis, 
	
	    \begin{tabular}{lll}
			$\mathsf{toGrammar}(T)$ & $= \varepsilon$\\
			$\mathsf{toGrammar}(X,U)$ & adds a production 
			$X \rightarrow a \enspace \mathsf{toGrammar}(U')$
		\end{tabular}\\\\
		then, considering $\vec X_U \leftarrow \mathsf{toGrammar}(X,U)$, 
		we notice that $X_U = X \enspace \vec X_U'$ for some sequence of 
		non-terminal symbols $\vec X_U'$. Hence, by congruence, we have a 
		transition 
		\[\mathsf{toGrammar}(S) = \enspace \varepsilon \enspace X \enspace 
		\vec X_U' \rightarrow \enspace a \enspace \mathsf{toGrammar}(U') \enspace 
		\vec X_U'.\]
\end{itemize}
\end{proof}

Conversely, we prove that any transition derived from the productions 
has a corresponding labelled transition in the \LTS.

\begin{lemma}
Given a session type $S$ and a label $\ell$,
	\[ \text{if } \mathsf{toGrammar}(S) \rightarrow \enspace \ell \enspace 
	 \vec Y \text{ then } S \LTSderives[\ell] S', \text{for some $S'$}.\]
\end{lemma}

\begin{proof}
	The proof is by induction on the structure of $S$:
	\begin{description}
		\item[Case $S \triangleq \skipk$:] $\mathsf{toGrammar}(S)$ does not 
		     add any production, and \DONE{S}.
		\item[Case $S \triangleq A$:] $\mathsf{toGrammar}(Y,S)$ adds the 
		     production $Y\rightarrow A$ and, in the LTS, $S \LTSderives[A] 
		     \skipk$, where $A$ ranges over $!B$, $?B$, and $\alpha$.
		\item[Case $S\triangleq \star \{\ell_i : S_i\}_{i\in I}$:] for each 
		     $j\in I$, $\mathsf{toGrammar}(Y,S)$ adds a production 
		     \linebreak $Y \rightarrow \star \ell_j \enspace 
		     \mathsf{toGrammar}(S_j)$. In the \LTS\ we also have 
		     $S_1 \LTSderives[\star \ell_j] S_j$, for each $j\in I$.
		\item[Case $S\triangleq \mu x.S$:] $\mathsf{toGrammar}(\_,S)$ adds, 
		     recursively, all productions from \linebreak$\mathsf{toGrammar}
		     (\mathsf{subst}(x,Y,S))$. Analogously, in the \LTS\ side, any transition 
		     $S[\mu x.S/x] \LTSderives[a] S'$ leads to a transition 
		     $\mu x.S \LTSderives[a] S'$.
		\item[Case $S \triangleq T;U$:] $\mathsf{toGrammar}(S)$ recursively adds 
		     all productions from  $\mathsf{toGrammar}(T)$ and, then, from $\mathsf{toGrammar}(U)$.
		     By induction hypothesis, all these productions have corresponding 
		     transitions in the \LTS.
	\end{description}
\end{proof}

Having proved that any labelled transition in the LTS has a corresponding
transition in the grammar and vice-versa, the following theorem is now 
immediate.

\begin{theorem}
\label{cfst_vs_grammar}
	Given two context-free session types $S_1, S_2$,
	\[ S_1 \TypeEquiv S_2 \text{ if and only if } X_{S_1} \ProdEquiv X_{S_2}. \]
\end{theorem}

\subsection{\textit{Unnormedness} is preserved}

To prove that the pruning stage is in accordance with the results 
from Christensen et al., we now observe that unnormed non-terminal symbols 
corresponding to (un)normed types are (un)normed. These results follow 
immediately from the previous results. 

\begin{corollary}
	Given a context-free session type $S$, $|S| = |\mathsf{toGrammar}(S)|$.
\end{corollary}

\begin{corollary}
	A context-free session type $S$ is unnormed if and only if 
	$X_S$ is unnormed.
\end{corollary}

\subsection{The expansion tree is correct}

Let us start by proving a small lemma, whose ultimate purpose 
stands on proving that all nodes excluded by the filtering rule
would lead to unsuccessful branches.

\begin{lemma}
\label{lemma:filtering}
	Let $(\vec X, \vec Y)$ be a pair in node $N$ of the expansion tree. 
	If $|\vec X| \neq |\vec Y|$ then  $\vec X \not\ProdEquiv \vec Y$.
\end{lemma}

\begin{proof}
	Assume that $n = |\vec X| < |\vec Y|$. This means that:
	\begin{equation}
	\label{pathX}
		\vec X \rightarrow \ell_1 \vec X_1 \rightarrow \cdots 
		\rightarrow \ell_n \rightarrow \varepsilon.
	\end{equation}
	Now assume that $\vec Y$ has an expansion sequence whose 
	labels coincide with those from $\vec X$ (otherwise, we would immediately
	have $\vec X \not\ProdEquiv \vec Y$). Since $\vec Y > n$, there should 
	exist a label $\ell_{n+1}$ such that:
	\[\vec Y \rightarrow \ell_1 \vec Y_1 \rightarrow \cdots 
	\rightarrow \ell_n \vec Y_n\rightarrow \ell_{n+1} \vec Y_n 
	\rightarrow \cdots\]
	Since our grammar is simple, \eqref{pathX} is the unique path from $\vec X$
	through labels $\ell_1, \ldots, \ell_n$. Hence, the $(n+1)$-th expansion of
	$\vec X$ with label $\ell_{n+1}$ would fail and we conclude that
	$\vec X \not\ProdEquiv \vec Y$.
\end{proof}

The \emph{safeness property} is paramount for the soundness of our algorithm:

\begin{proposition} [Safeness Property~\cite{janvcar1999techniques}]
\label{prop:safeness}
	$\vec X \ProdEquiv \vec Y$ if and only if the expansion tree rooted 
	at $\{(\vec X, \vec Y)\}$ has a successful branch.
\end{proposition}

\begin{proof}
	The reflexive, congruence and \BPA\ rules were already proved to 
	preserve the safeness property~\cite{janvcar1999techniques}.
	On the other hand, as observed in~\cite{janvcar1999techniques},
	the union of nodes along a successful branch is a relation $R$ 
	such that $R\subseteq \ProdEquiv$. Hence, any pair $(\vec X, \vec Y)$ 
	occurring along a successful branch is such that $\vec X \ProdEquiv \vec Y$,
	which, by Lemma~\ref{lemma:filtering}, means that $|\vec X|=|\vec Y|$.
	So, the filtering rule would node exclude any node in the successful branch
	and, then, also preserved the safeness property.
\end{proof}

The results on the soundness of the algorithm are now straightforward. 

\begin{theorem}
	If Algorithm~\ref{lst:algorithm} returns \textsf{true} on input 
	$(S_1,S_2)$, then $X_{S_1} \ProdEquiv X_{S_2}$.
\end{theorem}

\begin{proof}
	The algorithm returns \textsf{true} on input $(S_1,S_2)$ whenever 
	it reaches a finite successful branch in the expansion tree rooted 
	at $\{(X_{S_1}, X_{S_2})\}$. Since all rules preserve the safeness 
	property, if $\{(X_{S_1}, X_{S_2})\}$ has a (finite) successful 
	branch then $X_{S_1} \ProdEquiv X_{S_2}$.
\end{proof}

Using Theorem~\ref{cfst_vs_grammar}, the soundness of our algorithm is 
immediate:

\begin{theorem}
	Algorithm~\ref{lst:algorithm} is sound with respect to the meta-theory 
	of context-free session types, i.e., if it returns \textsf{true} then $S_1 \TypeEquiv S_2$.
\end{theorem}

Having observed that the safeness property was paramount for soundness, 
we now notice that the \emph{finite witness property} is of utmost 
importance to prove completeness.

\begin{proposition} [Finite Witness Property~\cite{janvcar1999techniques}]
\label{finite_witness}
	If $\vec X \ProdEquiv \vec Y$, then the expansion tree rooted at 
	$\{(\vec X, \vec Y)\}$ has a finite successful branch.
\end{proposition}

\begin{proof}
	The \BPA\ rules were proved to ensure the finite witness 
	property~\cite{janvcar1999techniques}. The remaining rules do not
	affect any successful branch: reflexive and congruence rules only remove 
	redundant pairs, because we all these results consider the least 
	congruence relation containing the union of the nodes in the 
	successful branch, whereas the filtering rule was proved to exclude 
	only unsuccessful branches (see Lemma~\ref{lemma:filtering} and proof 
	of Proposition~\ref{prop:safeness}).
\end{proof}

\begin{theorem}
	Algorithm~\ref{lst:algorithm} is complete with respect to the meta-theory 
	of context-free session types, i.e., if $S_1 \TypeEquiv S_2$ then 
	the algorithm returns \textsf{true}.
\end{theorem}

\begin{proof}
	Assuming that $S_1 \TypeEquiv S_2$, by Theorem~\ref{cfst_vs_grammar}, we 
	have $X_{S_1} \ProdEquiv X_{S_2}$. Hence, the finite witness property 
	ensures the existence of a finite successful branch on the expansion 
	tree rooted at $\{(X_{S_1},  X_{S_2})\}$. Since our algorithm traverses 
	the expansion tree using breadth-first search we will, eventually, 
	reach the finite successful branch and conclude the equivalence positively.
\end{proof}
