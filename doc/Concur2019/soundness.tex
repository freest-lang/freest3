\section{Correctness of the algorithm}
\label{sec:soundness}

In this section we prove that our algorithm is sound and complete
with respect to the meta-theory of context-free session types proposed
by Thiemann and Vasconcelos~\cite{thiemann2016context}.

We start by showing that the bisimulation relation on context-free
session types, $\TypeEquiv$, is equivalent to the bisimulation
relation obtained from the productions, $\ProdEquiv$.  Then, based on
results from Caucal~\cite{caucal1986decidabilite}, Christensen,
H{\"{u}}ttel, and Stirling~\cite{DBLP:journals/iandc/ChristensenHS95},
Jan{\v{c}}ar and Moller~\cite{janvcar1999techniques}, we conclude that
our algorithm is sound and complete.

\subsection{The two bisimulations coincide}

For the purpose of providing a bisimulation between context-free
session types and their corresponding symbols in the grammar, we start
with a lemma that relates terminated types~$S$ to the result of
$\toGrammarf S$.

\begin{lemma}
  \label{lem:terminated-togrammar}
  %% replaced P by \emptyset
  \DONE S if and only if $\varepsilon, \emptyset = \toGrammarf S$.
\end{lemma}

\begin{proof} Given that all variables in a type are under some
  $\mu$-binder, there is a simple inductive characterization of
  $\DONE S$, namely, $\DONE \skipk$, $\DONE{(S;T)}$ if $\DONE S$ and
  $\DONE T$, $\DONE{(\mu X.S)}$ if $\DONE S$, $\DONE X$, and false in
  all other cases. The proof then follows by a simple induction on
  this characterization for the ``if'' direction, and induction on
  \lstinline|toGrammar| for the ``only if'' direction.
\end{proof}

To conclude that the bisimulations on context-free session types and
those on productions coincide, we present a bisimilarity between
context-free session types and the result of \lstinline|toGrammar|.
%
As the implementation of \isCheckedf is not shown, we assume that
$\isCheckedf S$ returns \lstinline|True| if and only if $\DONE S$.
%
%% new from here
Consider the relation $\mathcal{R}$ given by:
\[\begin{array}{lll}
	\mathcal{R} = & \{ (\skipk, (\varepsilon, \emptyset))\} \,\cup\\
	& \{(\sharp B,(X,\{X \rightarrow \sharp B\})) \mid \text{$B$ is any base type}\} 
	   \,\cup\\
	& \{ (\star\{l_i\colon S_i\}_{i\in I}, (X, \{X \rightarrow \star l_i
    \vec Y_i\}_{i\in I} \cup (\cup  P_i)_{i\in I})) \mid 
    \begin{array}[t]{l}
    	\text{$S_i$ is any type, $l_i$ is any label,}\\
    	\text{$\vec Y_i, P_i = \toGrammarf{S_i}$, $i \in I$ }\\
    	\text{and $X$ does not occur in $P_i$}\} \,\cup\\
    \end{array}\\
    &\{(S_1;S_2, (\vec X_1\vec X_2,  P_1 \cup  P_2)) \mid
    \text{$S_i$ is any type, $\vec X_i, P_i = \toGrammarf{S_i}, i = 1,2$ } \}\,\cup\\
    & \{(\mu X.S, (\varepsilon, \emptyset)) \mid 
    \text{$S$ is any type and $\isCheckedf \mu X.S$}\}\,\cup\\
    & \{(\mu X.S, (X, \{X \rightarrow a_j \vec {Z_j}\vec Y\}_{j\in J} \cup  P)) \mid 
    \begin{array}[t]{l}
      \text{$S$ is any type, not } \isCheckedf \mu X.S,\\
      Y\vec Y, P = \toGrammarf{S}, \text{ $X$ does not}\\
      \text{occur in $P$ }\text{ and } \{Y \rightarrow a_j \vec {Z_j}\}_{j\in J} 
      \subseteq  P\\
      \text{are all the transitions from $Y$}\}
    \end{array}\\
\end{array}\]

\begin{lemma}
\label{lemma:bisim_unr}
	For any type $S$, if not $\isCheckedf \mu X.S$ and 
	$(\mu X.S, (X, \{X \rightarrow a_j \vec {Z_j}\vec Y\}_{j\in J} \cup  P))\in \mathcal{R}$
	with $\{Y \rightarrow a_j \vec {Z_j}\}_{j\in J}\subseteq P$, then
	$(\Unravel(\mu X.S), (X, \{X \rightarrow a_j \vec {Z_j}\vec Y\}_{j\in J} \cup  P))
	\in \mathcal{R}$.
\end{lemma}

\begin{proof}
	Notice that $\{Y \rightarrow a_j \vec {Z_j}\}_{j\in J}\subseteq P$ are 
	precisely the first 
	transitions from $\Unravel(\mu X.S)$. Furthermore, since 
	$\subs{\mu X.S}{X} S$ is obtained from $S$ by 
	replacing the occurrences of $X$ by $\mu X.S$, all the productions for
	$\subs{\mu X.S}{X} S$ 
	are given by the productions of $S$, as using $\mu X.S$
	instead of $X$ does not contribute with any new production on $S$.
\end{proof}

We remark that whenever a type $S$ has a transition, then $\isCheckedf S$
does not hold.

\begin{lemma}
\label{lemma:bisim_semi}
	$(S_1;S_2, (\vec X_1\vec X_2,  P_1 \cup  P_2))\in\mathcal{R}$ iff 
	$(S_i, (\vec X_i,  P_i))\in\mathcal{R}$, for $i=1,2$.
\end{lemma}
\begin{proof}
	Assume that $(S_1;S_2, (\vec X_1\vec X_2,  P_1 \cup  P_2))\in\mathcal{R}$
	and $(S_i, (\vec Y_i,  Q_i))\in\mathcal{R}$. Since 
	$ \vec X_i, P_i = \toGrammarf{S_i}$ and, by construction of $\mathcal{R}$,
	we necessarily have $ \vec Y_i, Q_i = \toGrammarf{S_i}$, it follows that
	$\vec Y_i = \vec X_i$ and $Q_i=P_i$. With a similar reasoning we prove the
	reciprocal implication.
\end{proof}

The same argument applies to the proof of the following lemma.

\begin{lemma}
\label{lemma:bisim_choice}
	$(\star\{l_i\colon S_i\}_{i\in I}, (X, \{X \rightarrow \star l_i
    \vec Y_i\}_{i\in I} \cup (\cup  P_i)_{i\in I}))\in\mathcal{R}$ iff 
	$(S_i, (\vec Y_i,  P_i))\in\mathcal{R}$, $i \in I$.
\end{lemma}

Now we prove that the relation $\mathcal{R}$ is a bisimilarity. We do it
by induction. For that, we use the unravelling function proposed 
in~\cite{thiemann2016context}:

\[\begin{aligned}
\Unravel(\mu x . S) &= \Unravel(\subs{\mu X.S}{X} S)\\
\Unravel(S_1;S_2) &= 
\begin{cases}
	\Unravel(S_2) & \Unravel(S_1)=\skipk\\
	\Unravel(S_1);S_2 & \Unravel(S_1)\neq\skipk\\
\end{cases} \\
\Unravel(S)&= S \text{  for all other cases}
\end{aligned}\]
%
Notice that for any recursive type 
$\mu X.S$, $\Unravel(\mu X.S)$ is not a recursive type and preserves the 
transitions from $\mu X.S$.

\begin{theorem}
\label{thm:cfst_vs_grammar}
	$\mathcal{R}$ is a bisimilarity.
\end{theorem}

\begin{proof}
	We prove that for each $(S, (\vec X, P))\in \mathcal{R}$	, if
	$S \LTSderives[a] T$ then $\vec X \rightarrow a \vec Y\in P$
	and $(T, (\vec Y, P'))\in \mathcal{R}$ for some $P'$. The proof is by
	induction on the structure of $S$. With this purpose, whenever $S$ is a 
	recursive type, we reduce the analysis to $\Unravel(S)$, that
	is not recursive. Indeed, without loss of generality, 
	we can always reduce the analysis of $S$
	to the analysis of $\Unravel(S)$
	because when $S$ is not recursive we have
	$\Unravel(S)=S$.
	\begin{itemize}
		\item $(\skipk, (\varepsilon, \emptyset))$: $\skipk$ does not have any
		transition.
		\item $(\sharp B,(X,\{X \rightarrow \sharp B\}))$: by the \LTS,
		$\sharp B\LTSderives[\sharp B] \skipk$ and $X\rightarrow \sharp B$ with
		$(\skipk, (\varepsilon, \emptyset))\in \mathcal{R}$.
		\item $(\star\{l_i\colon S_i\}_{i\in I}, (X, \{X \rightarrow \star l_i
    	\vec Y_i\}_{i\in I} \cup (\cup  P_i)_{i\in I}))$: 
    	$\star\{l_i\colon S_i\}_{i\in I}\LTSderives[l_i] S_i$ and 
    	$X \rightarrow \star l_i \vec Y_i$ for each $i\in I$. By 
    	lemma~\ref{lemma:bisim_choice}, $(S_i, (\vec Y_i,  P_i))\in\mathcal{R}$
    	for each $i\in I$. 
    	\item $(S_1;S_2, (\vec X_1\vec X_2,  P_1 \cup  P_2))$: start noting
    	that, by lemma~\ref{lemma:bisim_semi}, 
    	$(S_i, (\vec X_i, P_i))\in \mathcal{R}$ for $i=1,2$. 
    	\begin{itemize}
    	\item if 
    	$S_1;S_2\LTSderives[a] S_1'; S_2$ with $S_1\LTSderives[a] S_1'$, then 
    	$\Unravel(S_1)\LTSderives[a] S_1'$ (recall that $\Unravel(S_1)=S_1$ when
    	$S_1$ is not recursive). 
    	Since $(S_1,(\vec X_1, P_1))\in\mathcal{R}$, we have
    	$(\Unravel(S_1), (\vec X_1, P_1))\in \mathcal{R}$ 
    	(if $S_1$ is not a recursive type, $\Unravel(S_1)$ 
    	coincides with $S_1$, otherwise apply lemma~\ref{lemma:bisim_unr}).
    	Hence, by induction hypothesis on $\Unravel(S_1)$, we know that 
    	$\vec X_1 \rightarrow a \vec Y_1$ and 
    	$(S_1', (\vec Y_1,P_1'))\in \mathcal{R}$. 
    	By lemma~\ref{lemma:bisim_semi}, we conclude that 
    	$(S_1';S_2, (\vec Y_1 \vec X_2,P_1'\cup P_2))\in \mathcal{R}$. 
    	\item if $S_1;S_2\LTSderives[a] S_2'$, where $\DONE{S_1}$ and 
    	$S_2\LTSderives[a] S_2'$, it follows that 
    	$\Unravel(S_2)\LTSderives[a] S_2'$. 
    	Since $(S_2, (\vec X_2, P_2))\in \mathcal{R}$ we have 
    	$(\Unravel(S_2), (\vec X_2, P_2))\in \mathcal{R}$ (again, 
    	if $S_2$ is not a recursive type $\Unravel(S_2)=S_2$, 
    	otherwise use lemma~\ref{lemma:bisim_unr}). 
    	By induction hypothesis on $\Unravel(S_2)$, we thus have
    	$\vec X_2 \rightarrow a \vec Y_2$ where 
    	$(S_2', (\vec Y_2,P_2'))\in \mathcal{R}$. Since $\DONE{S_1}$, by
    	lemma~\ref{lem:terminated-togrammar} we have $\vec X_1 = \varepsilon$, 
    	hence $\vec X_1 \vec X_2 = \vec X_2 \rightarrow a \vec Y_2$.
    	\end{itemize}
    	\item $(\mu X.S, (\varepsilon, \emptyset))$: in this case, 
    	$\isCheckedf \mu X.S$, thus
    	we do not have any transition (lemma~\ref{lem:terminated-togrammar}).
    	\item $(\mu X.S, (X, \{X \rightarrow a_j \vec {Z_j}\vec Y\}_{j\in J} \cup  P))$: 
    	if $\mu X.S\LTSderives[b] T$, then $\Unravel(\mu X.S)\LTSderives[b] T$.
    	Furthermore, by lemma~\ref{lemma:bisim_unr} we know that 
    	$(\Unravel(\mu X.S), (X, \{X \rightarrow a_j \vec {Z_j}\vec Y\}_{j\in J} \cup  P))
    	\in\mathcal{R}$. By induction hypothesis on $\Unravel(\mu X.S)$, 
    	and since $X$ does not occur in $P$, it follows 
    	that $b=a_j$ for some $j\in J$ and $(T, (\vec Z_j \vec Y, P'))\in \mathcal{R}$.
	\end{itemize} 
	The proof that any transition in the productions leads to a transition in 
	the corresponding type is very similar and is also done by induction. 
	For that,
	we only need to recall that the variable $X$ is a fresh variable and, thus, 
	the transitions from $X$ are simply the ones explicitly detailed in each 
	pair from $\mathcal{R}$.
\end{proof}


%% new until here

%% old proof here
%\begin{theorem}
%\label{thm:cfst_vs_grammar}
%  $S$ is bisimilar to $\toGrammarf{S}$.
%\end{theorem}
%
%\begin{proof}
%  Let $\mathcal R$ be the binary relation on types $\times$ (words
%  $\times$ productions) that contains the following sets of pairs
%  $(S, (\vec X, P))$ built in such a way that $\vec X, P = \toGrammarf S$.
%  %
%  \begin{gather*}
%    (\skipk, (\varepsilon, \emptyset))
%    \\
%    (\sharp B, (X, \{X \rightarrow \sharp B\}))
%    \\
%    (\star\{l_i\colon S_i\}_{i\in I}, (X, \{X \rightarrow \star l_i
%    \vec Y_i\}_{i\in I} \cup (\cup  P_i)_{i\in I}))
%    %
%    \text{ when } \vec Y_i, P_i = \toGrammarf{S_i}, i \in I
%    % \\
%    % (S_i, (\vec Y_i, \{X \LTSderivesP[\star l_i]
%    % \vec Y_i\}_{i\in I} \cup (\cup  P_i)_{i\in I}))
%    % %
%    % \text{ when } \vec Y_i, P_i = \toGrammarf{S_i}, i \in I
%    \\
%    (S_1;S_2, (\vec X_1\vec X_2,  P_1 \cup  P_2))
%    %
%    \text{ when } \vec X_i, P_i = \toGrammarf{S_i}, i = 1,2
%    % \\
%    % (S'_1;S_2, (\vec Y,  P_1 \cup  P_2))
%    % %
%    % \text{ and, in addition, } S_1 \LTSderives S_1' 
%    % \text{ and } \vec X_1\vec X_2 \rightarrow a \vec Y
%    % \\
%    % (S_2', (\vec Y,  P_1 \cup  P_2))
%    % %
%    % \text{ and, in addition, } \DONE{S_1}
%    % \text{ and } S_2 \LTSderives S_2' 
%    % \text{ and } \vec X_1\vec X_2 \rightarrow a \vec Y
%    \\
%    (\mu X.S, (\varepsilon, \emptyset))
%    \text{ when } \isCheckedf \mu X.S
%    \\
%    (\mu X.S, (X, \{X \rightarrow a \vec Z\vec Y\} \cup  P))
%    %
%    \text{ when not }  \isCheckedf \mu X.S \text{ and }
%    \\\quad
%    Y\vec Y, P = \toGrammarf{S}
%    \text{ and }
%    Y \rightarrow a \vec Z \in  P
%   %  \\
%   %  (T, (\vec Z\vec Y, \{X \LTSderivesP \vec Z\vec Y\} \cup  P))
%   %  %
%   %  \text{ and, in addition, } Y \LTSderivesP \vec Z
%   % \text{ and } \subs{\mu X.S}{X} S \LTSderives T
%  \end{gather*}
%  %
%  That $\mathcal R$ is a bisimulation follows by co-induction, using
%  Lemma~\ref{lem:terminated-togrammar}. % and the fact that
%  % $S \bisim \subs{\mu X.S}{X} S$~\cite{thiemann2016context}.
%\end{proof}

% We start by showing that the initial (dummy) production does not
% affect bisimulation checking.
% %
% \begin{lemma}
%   \label{lem:dummy}
%   $X_S \ProdEquiv X_T$ if and only if
%   $\toGrammarf S \ProdEquiv \toGrammarf T$.
% \end{lemma}

% \begin{proof}
%   We have $X_S \rightarrow\, \initialProd\,(\toGrammarf S)$ and
%   $X_T \rightarrow\, \initialProd\,(\toGrammarf T)$.
%   Hence, $X_S \TypeEquiv X_T$ if and only if
%   $\toGrammarf S \ProdEquiv \toGrammarf T$. \vv{prove both directions separately}
% \end{proof}

% Terminated session types do not originate new productions.

% \begin{lemma}
%   \label{lemma:terminated_session}
%   If \DONE{S}, then \upshape{\lstinline|toGrammar |}$S$ adds no
%   productions and returns \upshape{\lstinline|[]|}.
% \end{lemma}

% \begin{itemizeproof}
%   By rule induction  on the hypothesis.
%   \begin{itemize}
%   \item If $S\triangleq \skipk$, then \lstinline{toGrammar} adds no
%     productions and returns \lstinline{[]}.
%   \item If $S\triangleq S;T$, then \DONE S and \DONE T. By induction,
%     the recursive calls add no productions and return
%     \lstinline|[]|. Then, function \lstinline|toGrammar| returns
%     \lstinline|[]++[]|, which evaluates to \lstinline|[]|.
%   \item If $S\triangleq \mu X. T$, then
%     $\subs{S}{X}T \checkmark$.
%     %
%     Function \lstinline|toGrammar |$S$ adds the productions from
%     \lstinline|toGrammar (subs (Var y) X t)|. But $\subs{S}{X} T$ is a
%     terminated session, thus \lstinline{toGrammar }$T$ adds no
%     productions and returns \lstinline{[]}. \vv{co-induction?}.
%   \end{itemize}
% \end{itemizeproof}

% Now we prove that any transition in the \LTS\ has a
% corresponding transition derived from the set of productions.

% \begin{lemma}
%   \label{lem:type-to-prod}
%   If $S \LTSderives T$, then \upshape{\lstinline|toGrammar|}
%   $S \LTSderivesP \vec X$ and \upshape{\lstinline|toGrammar|} $T$ is a
%   prefix of~$\vec X$.
% \end{lemma}

% \begin{itemizeproof}
% By rule induction on the hypothesis.
% \begin{itemize}
% \item If $S\triangleq \sharp B$, then
%   $S \LTSderives[\sharp B] \skipk$. The call $\toGrammarf S$
%   returns a fresh variable $Y$ and inserts a production
%   $Y\rightarrow \sharp B$. Then $S \LTSderivesP \varepsilon$ and
%   $\toGrammarf\,\skipk =$ \lstinline{[]}, that is, $\varepsilon$.
% \item If $S\triangleq \star\{l_i``\colon S_i\}_{i\in I}$ then,
%   $S \LTSderives[\star l_j] S_j$, for each $j\in I$. Function
%   $\toGrammarf S$ returns a fresh variable $Y$ and, recursively,
%   inserts a production $Y\rightarrow \star l_j (\toGrammarf{S_j})$,
%   for each $j\in I$, hence
%   $Y \LTSderivesP[\star l_j] \toGrammarf{S_j}$.
% \item If $S\triangleq T;U$ and $T \LTSderives[a] T'$, then
%   $S \LTSderives[a] T';U$.  By induction hypothesis, $\toGrammarf T$
%   adds the production $Y\rightarrow a (\toGrammarf{T'})$, where $Y$
%   is a fresh variable.  We notice that $\toGrammarf T$
%   $= Y \vec Y_T$ for some sequence of non-terminal symbols
%   $\vec Y_T$. By congruence, we have:
%   \[\toGrammarf S = Y\vec Y_T(\toGrammarf U)
%     \rightarrow a(\toGrammarf T')\vec Y_T(\toGrammarf U)
%     .\]
% \item If $S\triangleq \mu x.T$, then $\subs SXT \LTSderives T'$.
%   By induction, the corresponding production in
%   %
%   \lstinline{toGrammar (subs (Var y) x t)} is recursively added by
%   $\toGrammarf S$ in the form $Y \rightarrow a (\toGrammarf{T'})$,
%   where $Y$ is a fresh variable that is, then, returned by
%   $\toGrammarf S$.
% \item If $S\triangleq T;U$, $T$ is a terminated session, with no further
%   action, and $U \LTSderives[a] U'$ then, using the \LTS\ we have
%   $T;U \LTSderives[a] U'$. On the other hand, by induction hypothesis and
%   using Lemma~\ref{lemma:terminated_session}:
%   \begin{itemize}
%   \item $\toGrammarf T$  returns \lstinline{[]},
%   \item $\toGrammarf U$ adds a production
%     $Y \rightarrow a (\toGrammarf U')$, where $Y$ is a fresh
%     variable.
%   \end{itemize}
%   We notice that $\toGrammarf U = Y\vec Y_U$ for some sequence of
%   non-terminal symbols $\vec Y_U$. Hence, by congruence, we have a
%   transition
%   \[\toGrammarf S = \text{\lstinline{[]}} Y
%     \vec Y_U \rightarrow a (\toGrammarf{U')} \vec Y_U.\]
% \end{itemize}
% \end{itemizeproof}

% Conversely, we prove that any transition derived from the productions
% has a corresponding labelled transition in the \LTS.

% \begin{lemma}
%   \label{lem:prod-to-type}
%   If $\toGrammarf S \LTSderivesP \vec Y$, then $S\LTSderives
%   T$.\\ \vv{and there must be some relation on $\vec Y$ and $T$, for
%     induction purposes}
% \end{lemma}

% \begin{itemizeproof}
%   By induction on the structure of $S$: \vv{redo}
%   \begin{itemize}
%   \item If $S \triangleq \sharp B$, then $\toGrammarf S$ adds the
%     production $Y\rightarrow \sharp B$ and we know that
%     $S \LTSderivesP[\sharp B] \skipk$.
%   \item If $S\triangleq \star \{\ell_i : S_i\}_{i\in I}$, then
%     $\toGrammarf S$ recursively adds
%     $\toGrammarf S \rightarrow \star \ell_j(\toGrammarf{Sj})$ for each
%     $j\in I$. In the \LTS\ for productions we also have
%     $S \LTSderivesP[\star\ell_j] S_j$ for each $j\in I$.
%   \item If $S \triangleq T;U$, then $\toGrammarf S$ recursively adds
%     all productions from $\toGrammarf T$ and from $\toGrammarf
%     U$. Hence, if $\toGrammarf S \LTSderivesP \vec Y$ then, either:
%     \begin{itemize}
%     \item $\toGrammarf T \LTSderivesP \vec Y$ and, in this case, by
%       induction we know that $T \LTSderives T'$ and from the \LTS\ for
%       productions we obtain $S \LTSderivesP T';U$;
%     \item \DONE{T} and $\toGrammarf U \rightarrow a\vec Y$ and, by
%       induction we know that $U \LTSderives[a] U'$ and from the \LTS\
%       for productions we obtain $S \LTSderives U'$.
%     \end{itemize}
%   \item If $S\triangleq \mu x.T$, then $\toGrammarf S$ adds,
%     recursively, all productions from
%     %
%     \lstinline|toGrammar (subs (Var y) x t)|.  Analogously, in the
%     \LTS\ for productions, any transition $\subs SXT \LTSderives T'$
%     leads to a transition $S \LTSderives T'$. \vv{Why?}
%   \end{itemize}
% \end{itemizeproof}

% Having proved that any labelled transition in the LTS has a corresponding
% transition in the grammar and vice-versa, the following theorem is now
% immediate.

% \begin{theorem}
%   \label{thm:cfst_vs_grammar}
%   $S\TypeEquiv T$  if and only if $ X_S \ProdEquiv X_T$.
% \end{theorem}

% \begin{proof}
%   From lemmas~\ref{lem:dummy}, \ref{lem:type-to-prod}, and~\ref{lem:prod-to-type}.
% \end{proof}

% \subsection{Unnormedness is preserved by pruning} % Not needed?

% To prove that the pruning stage is in accordance with the results from
% Christensen et al.~\cite{DBLP:journals/iandc/ChristensenHS95}, we
% observe that unnormed non-terminal symbols corresponding to (un)normed
% types are (un)normed. These results follow immediately from the
% previous results. \vv{from which results, exactly?}

% \begin{corollary}
%   Given a context-free session type $S$, $|S| = |\toGrammarf S|$.
% \end{corollary}

% \begin{corollary}
%   A context-free session type $S$ is unnormed if and only if $X_S$ is
%   unnormed.
% \end{corollary}

% \vv{these notions are not defined on session types}

\subsection{Correctness of the algorithm}

We now focus on the correctness of the algorithm in
Listing~\ref{lst:algorithm}.  Before proceeding to soundness, we
recall the \emph{safeness property} presented by Jan{\v{c}}ar and
Moller.

\begin{proposition} [Safeness Property \cite{janvcar1999techniques}]
  \label{prop:safeness}
  $\vec X \ProdEquiv \vec Y$ if and only if the expansion tree rooted
  at $\{(\vec X, \vec Y)\}$ has a successful branch.
\end{proposition}

Notice that function \lstinline|bisimilar|
(Listing~\ref{lst:algorithm}) builds an expansion tree by alternating
between expansion and simplification operations (reflexive,
congruence and \BPA\ rules), as proposed by Jan{\v{c}}ar and Moller.
%
These simplification rules are \emph{safe}~\cite{janvcar1999techniques}, in the sense that the
application of any rule preserves the bisimulation from a parent node
to at least one child node and, reciprocally, that bisimulation on a
child node implies the bisimulation of its parent node, thus proving
the safeness property.

%\begin{proof}
%	On the other hand, as observed in~\cite{janvcar1999techniques},
%	the union of nodes along a successful branch is a relation $R$
%	such that $R\subseteq \ProdEquiv$. Hence, any pair $(\vec X, \vec Y)$
%	occurring along a successful branch is such that $\vec X \ProdEquiv \vec Y$,
%	which, by Lemma~\ref{lemma:filtering}, means that $|\vec X|=|\vec Y|$.
%	So, the filtering rule would node exclude any node in the successful branch
%	and, then, also preserved the safeness property.
%\end{proof}

\begin{lemma}
  \label{lem:bisimilar-to-prod}
  If $\bisimf S T$ returns \upshape{\lstinline|True|}, then
  $X_{S} \ProdEquiv X_{T}$.
	% Given two context-free session types $S$ and $T$, if the function
	% \lstinline|equivalent|, presented in Listing~\ref{lst:algorithm},
	% returns \lstinline|true|, then $X_{S} \ProdEquiv X_{T}$.
\end{lemma}

\begin{proof}
  Function \lstinline|bisimilar| returns \lstinline|True| for $S$ and
  $T$ whenever it reaches a (finite) successful branch in the expansion
  tree rooted at $\{(X_{S}, X_{T})\}$. Conclude with the safeness property,
  Proposition~\ref{prop:safeness}.
  % , whenever the expansion tree rooted
  % at $\{(X_{S}, X_{T})\}$ has a (finite) successful branch, we
  % kn that $X_{S} \ProdEquiv X_{T}$.
\end{proof}

From the previous results, the soundness of our algorithm is now
immediate: the algorithm to check the bisimulation of context-free
session types (Listing~\ref{lst:algorithm}) is sound with respect to
the meta-theory of context-free session types.

\begin{theorem}
  If $\bisimf ST$ returns \upshape{\lstinline|True|} then $S\TypeEquiv T$.
\end{theorem}

\begin{proof}
  From Theorem~\ref{thm:cfst_vs_grammar} and
  Lemma~\ref{lem:bisimilar-to-prod}.
\end{proof}

Having observed that the safeness property was paramount for
soundness, we now notice that the \emph{finite witness property} is of
utmost importance to prove completeness. This result follows
immediately from the analysis by Jan{\v{c}}ar and
Moller~\cite{janvcar1999techniques}, which capitalizes on results by
Caucal~\cite{caucal1986decidabilite}, and Christensen, H{\"{u}}ttel, and
Stirling~\cite{DBLP:journals/iandc/ChristensenHS95}:

\begin{proposition} [Finite Witness Property]
\label{finite_witness}
	If $\vec X \ProdEquiv \vec Y$, then the expansion tree rooted at
	$\{(\vec X, \vec Y)\}$ has a finite successful branch.
\end{proposition}

We refer to Caucal, Christensen, H{\"{u}}ttel, and Stirling for
details on the proof of existence of a finite witness, as stated in
Proposition~\ref{finite_witness}. This proof is particularly
interesting in that it highlights the importance of BPA rules and of
pruning productions on reaching such (finite) witness. The results in
these two papers also allow us to unravel the reason for the
distinction of the simplification phase in the case where all the
symbols in the grammar are normed from the case where they are not, as
presented in Listing~\ref{lst:algorithm}.

Proposition~\ref{finite_witness} paved the way to obtain the completeness result. 
We now prove that the algorithm to check the bisimulation of context-free session 
types is complete with respect to the meta-theory of context-free session
types.

\begin{theorem}
  If $S \TypeEquiv T$ then $\bisimf S T$ returns
  \upshape{\lstinline|True|}.
\end{theorem}

\begin{proof}
  Assuming that $S \TypeEquiv T$, by Theorem~\ref{thm:cfst_vs_grammar}
  we have $X_{S} \ProdEquiv X_{T}$.  Hence, the Proposition~\ref{finite_witness}
  ensures the existence of a finite successful branch on the
  expansion tree rooted at $\{(X_{S},X_{T})\}$, i.e., a branch
  terminating in an empty node.  Since our algorithm traverses the
  expansion tree using breadth-first search it will, eventually, reach
  the empty node and conclude the bisimulation positively.
\end{proof}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
