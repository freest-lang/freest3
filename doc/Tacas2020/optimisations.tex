\section{Optimisations}
\label{sec:optimisations}

Armed with the results in Sections~\ref{sec:algorithm}
and~\ref{sec:correctness}, we decided to benchmark the algorithm on a
test suite of carefully crafted pair of types (more on this in
Section~\ref{sec:evaluation}). During this process we came across a
pair of types,
%
\begin{gather*}
    \mu X . \&\{ \mathsf{Add}\colon X;X; !\intk,
    \mathsf{Const}\colon ?\intk;!\intk,
    \mathsf{Mult}\colon X;X;!\intk \}
    \\
    \mu Y . \&\{ \mathsf{Add}\colon Y;Y,
    \mathsf{Const}\colon ?\intk,
    \mathsf{Mult}\colon Y;Y \}; !\intk
\end{gather*}
%
on which our algorithm took 4379.98 seconds (that is one hour and
forty minutes) to terminate. This is certainly not a reasonable
running time for such small pair of types. Hence we
looked into ways of improving the running time. 
We implemented the
following variants: 
\begin{enumerate}
	\item eliminating redundant productions in the grammar,
	\item using a double-ended queue where promising children are
prepended rather than appended,
	\item adding a filter rule to
simplification stage that removes hopeless pairs from nodes,
	\item iterating the simplification stage until a fixed point is reached.
\end{enumerate}


%Among the different
%optimisations that we tried, four stand out:
%%
%\begin{enumerate}
%\item Eliminate redundant productions in the grammar;
%\item Use a double-ended queue where promising children are prepended
%  rather than appended;
%\item Add a filter rule to simplification stage that removes hopeless
%  pairs from nodes;
%\item Iterate the simplification stage until a fixed point is reached.
%\end{enumerate}

% 1 _ ELIMINATE REDUNDANT PRODUCTIONS IN THE GRAMMAR

Realising that the size of the expansion tree depends, among other
things, on the number of productions in the grammar, we looked into
ways of generating smaller grammars. New productions are created in
function $\word$, cases $\sharp B$ and $\star\{l_i\colon
T_i\}$. Rather than blindly adding a new production
$Y \rightarrow \vec Z$, we look, in the set of productions, for a
production $W \rightarrow \vec X$ such that the language generated
from $\vec Z$ coincides with that from $\vec X$. In this
case, we add no new production and return non-terminal~$W$ instead. To
find~$W$, we look for the least fixed-point of transition labels in the
languages generated by $\vec Z$ and $\vec X$ and compare them.

% the generation of
% grammars cleaned of redundant terminal symbols is paramount to reduce
% the size of the expansion tree and thus to enhance the performance. We
% define a function \lstinline|addBasicProd| (see Appendix) that avoids
% the blind creation of fresh variables in function
% \lstinline|toGrammar| case \lstinline|Message p b| (in
% Listing~\ref{lst:toGrammar}) by a prior search for existing
% productions with the respective terminal symbols.

% 2 _ DOUBLE-ENDED QUEUE

A double-ended queue would allow prioritizing nodes with potential to
reach an empty node faster.
%
%
%% 3 _ FILTER
%
%\vv{filter}
%
%
If, on the one hand, we believed that the computation of the expansion
tree could be speeded up by extending the simplification phase, on the
other hand we suspected that a double-ended queue would allow
prioritizing nodes with potential to reach an empty node faster.
%
Iterating the simplification procedure on a given node $N$, the
algorithm computes the simplest possible children nodes derived from
$N$. Of course, we need to make sure that a fixed-point exists, which
we do with Theorem~\ref{thm:fixed_point}.
%
Using a double-ended queue, the algorithm prepends (rather than
appends) nodes that are already empty or whose pairs $(\vec X, \vec Y)$
are such that $|\vec X|\leq 1$ and $|\vec Y| \leq 1$. A filtering rule
ensures that nodes composed by pairs of types with different norms (if normed)
are removed from the expansion tree, since these types are not equivalent. 
Notice that the filtering rule preserves the results of soundness and 
completeness.
%
%The revised \lstinline|simplify| function is in Listing~\ref
%{lst:enhanced}.

% The next theorem shows that the simplification function that consists
% in applying the reflexive, congruence and \BPA\ rules has a fixed
% point.  The result applies regardless of whether all nonterminal
% symbols symbols are normed or not.

\begin{theorem}
  \label{thm:fixed_point}
  The simplification function that results from applying the
  reflexive, congruence, \BPA, and filtering rules, has a fixed point
  in the complete partial ordered set of pairs node-ancestors, where
  the set of ancestors is supposed to be fixed.
\end{theorem}
%
\begin{proof}
For the proof, consider the order $\leqSets$, defined on the
  $\text{\lstinline{Set (Node, Ancestors)}} \times
  \text{\lstinline{Set (Node, Ancestors)}}$, as $s_1 \leqSets s_2$ if
  there exists an injective map
  $\sigma : s_1 \rightarrow s_2$ s.t.\ $\sigma(n_1,a) = (n_2,a)$ with
  $n_2\subseteq n_1$. We prove that $\leqSets$ is a partial order and the 
  the simplification function is order-preserving. 
  We conclude that $(\text{\lstinline{Set (Node, Ancestors)}}, \leqSets)$ is
  a complete lattice and use Tarski's fixed point 
  theorem~\cite{tarski1955lattice}, to
  ensure that the simplification function has a fixed point in
  $\text{\lstinline{Set (Node, Ancestors)}}$.
  We omit the details due to space constraints.
%  \vv{where do we place the proof? Also, added one more rule:
%    filtering. Do we still have a theorem?}
\end{proof}

% We can now adapt the simplification phase to, on the one hand, iterate
% the simplification rules until reaching a fixed point and, on the
% other hand, identify and prepend promising nodes. An improved version
% of the \lstinline|simplify| function (Listing~\ref{lst:algorithm}) is
% in Listing~\ref{lst:enhanced}.

% \begin{lstlisting}[
%   caption={Haskell code for the improved simplification step (replaces
%     function \lstinline|simplify| in Listing~\ref{lst:algorithm})},
%   label={lst:enhanced},
%   captionpos=b]
% simplify :: Int -> Productions -> Node -> Ancestors -> NodeQueue -> NodeQueue
% simplify i ps n a q =
%   Queue.sortOn (lengthP i) (foldr enqueueNode q (findFixedPoint ps (Set.singleton (n, a))))

% enqueueNode :: (Node,Ancestors) -> NodeQueue -> NodeQueue
% enqueueNode (n,a) q 
%  | maxLength n <= 1 = (n,a) Queue.<| q
%  | otherwise        = q Queue.|> (n,a)

% findFixedPoint :: Productions -> Set.Set (Node,Ancestors) -> Set.Set (Node,Ancestors)
% findFixedPoint ps nas
%   | nas == nas' = nas
%   | otherwise   = findFixedPoint ps nas'
%   where nas' = if allNormed ps
%      then foldr (apply ps) nas [reflex,congruence,bpa2,filtering]
%      else foldr (apply ps) nas [reflex,congruence,bpa1,bpa2,filtering]

% \end{lstlisting}

The optimisations we propose aim at improving the performance of the
algorithm, however the branching nature of the expansion tree promotes
an exponential complexity: each simplification step (potentially)
generates a polynomial number of nodes, each of which with linear size
on the size of the input.  In turn, the same simplification phase may,
in the worst case, be iterated a linear number of times on the size of
the input.  For these reasons the complexity turns out to be (at least)
exponential.  Nevertheless, these heuristics seem to work quite well
in practice, as we show in the next section.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
